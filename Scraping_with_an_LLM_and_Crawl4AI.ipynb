{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5JjV9OQoE0Y"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Crawl4AI - Advanced Web Crawling and Data Extraction\n",
        "\n",
        "GitHub Repository: https://github.com/unclecode/crawl4ai\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary dependencies\n",
        "!sudo apt-get update && sudo apt-get install -y libwoff1 libopus0 libwebp6 libwebpdemux2 libenchant1c2a libgudev-1.0-0 libsecret-1-0 libhyphen0 libgdk-pixbuf2.0-0 libegl1 libnotify4 libxslt1.1 libevent-2.1-7 libgles2 libvpx6 libxcomposite1 libatk1.0-0 libatk-bridge2.0-0 libepoxy0 libgtk-3-0 libharfbuzz-icu0\n",
        "!pip install crawl4ai\n",
        "!pip install nest-asyncio\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "OehQHuKNoZZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from crawl4ai.extraction_strategy import JsonCssExtractionStrategy, LLMExtractionStrategy\n",
        "import json\n",
        "import os\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "x54gBqKQoZe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply nested asyncio for compatibility in certain environments (e.g., Jupyter/Colab)\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Nrwg8PHjoZhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-proj-xxxx'\n"
      ],
      "metadata": {
        "id": "XHiW_sKAoZjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for review extraction\n",
        "class UserReviewSchema(BaseModel):\n",
        "    title: str = Field(..., description=\"Title of the review\")\n",
        "    body: str = Field(..., description=\"Body text of the review\")\n",
        "    rating: int = Field(..., description=\"Rating given in the review\")\n",
        "    reviewer: str = Field(..., description=\"Name of the reviewer\")\n"
      ],
      "metadata": {
        "id": "5h9EASDsoZmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract user reviews with pagination handling\n",
        "async def extract_user_reviews_with_pagination():\n",
        "    async with AsyncWebCrawler(verbose=True) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url='https://example.com/product-page',  # Replace with your target product URL\n",
        "            word_count_threshold=1,\n",
        "            extraction_strategy=LLMExtractionStrategy(\n",
        "                provider=\"openai/gpt-4o-mini-2024-07-18\",\n",
        "                api_token=os.getenv('OPENAI_API_KEY'),\n",
        "                schema=UserReviewSchema.schema(),\n",
        "                extraction_type=\"schema\",\n",
        "                instruction=\"\"\"\n",
        "                From the crawled content, extract user reviews in the following format:\n",
        "                {\n",
        "                    \"reviews_count\": 100,\n",
        "                    \"reviews\": [\n",
        "                        {\n",
        "                            \"title\": \"Review Title\",\n",
        "                            \"body\": \"Review body text\",\n",
        "                            \"rating\": 5,\n",
        "                            \"reviewer\": \"Reviewer Name\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "                Ensure the response includes all reviews across pagination.\n",
        "                \"\"\"\n",
        "            ),\n",
        "            bypass_cache=True,  # Ignore any cached data for fresh crawling\n",
        "            pagination=True,  # Enable pagination handling\n",
        "            pagination_selector=\"button.next-page\"  # Adjust this CSS selector for the 'Next Page' button\n",
        "        )\n",
        "        # Print the extracted reviews in JSON format\n",
        "        print(json.dumps(result.extracted_content, indent=4))\n",
        "\n",
        "# Run the function\n",
        "await extract_user_reviews_with_pagination()"
      ],
      "metadata": {
        "id": "JWVOHDWLoZoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Moh-4b1IoZqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}